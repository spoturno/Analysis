{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of derivatives by incremental quotients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let f be a real funcion $\\ f(x): \\mathbb R \\rightarrow \\mathbb R,f\\in\\ C^2$ let's remember the definition of first derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f'(a) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not possible to calculate limits numerically, therefore, it is necesarry to estimate it. We will see below, different ways to carry out this approach. To calculate it numerically, aproximations are made, such as the incremental quotient $\\Delta_f(x),h$ for a small step $h \\in \\mathbb R^+$\n",
    "\n",
    "Also, we'll analize the mistakes made when computing this problem. There are two sources of error that we will analyze:\n",
    "- The error due to not working without infinite precision, which we will call rounding error\n",
    "- The eror due to truncation of taylor infinite series, which we will call the truncation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Forward difference\n",
    "This aproximations consist of aproximating the funcion derivative as the incremental quotient. Using the point itself $x$ and $+h$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Delta_f(x),h = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate an upper bound for the absolute error between the real value of the derivative and the floating point representation of the incremental quotient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Error_{absolute} = \\left |{f'(x)- \\frac{FP(f(x+h)) - FP(f(x))}{h}} \\right | $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\cdots = \\left | {f'(x) - \\Delta_f(x),h + \\Delta_f(x),h - \\frac{FP(f(x+h)) - FP(f(x))}{h}} \\right | $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\cdots \\leq \\left | f'(x) - \\Delta_f(x),h \\right | + \\left | \\Delta_f(x),h - \\frac{FP(f(x+h)) - FP(f(x))}{h} \\right |$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Error_{absolute} \\leq Error_{trunc} + Error_{FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error has two components, the first is because of the truncation of desired terms in taylor series, the other is the floating point representation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncation Error\n",
    "Taylor series in point $x$, using Lagrange's expresion for the rest:\n",
    "$$ f(x+y) = f(x) + f'(x)h + f''(c)\\frac{h^2}{2} \\hspace{1cm} c \\in [x, x+h].$$\n",
    "So, we can clear the quotient of the $h$ step:\n",
    "$$ \\Delta_f(x),h - f'(x) = \\frac{f(x+h) - f(x)}{h} - f'(x) = f''(c)\\frac{h}{2}$$\n",
    "So, we get a good aproximation for truncation error:\n",
    "$$Error_{trunc} = \\frac{|f''(c)|}{2}h \\approx \\frac{|f''(x)|}{2}h $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is concluded that the truncating error is of order h. This means that the error linearly decreases as h decreases. In the above reasoning, the last aproximation is based on assuming that $f''$ does not change too much between $x$. This hipotesis is not always valid, but It will be if we ask $f''$ to be continous $(f \\in C^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point Error\n",
    "$$FP(f(x+h)) = f(x+h)(1 + \\delta_h),\\hspace{0.5cm} |\\delta_h|\\leq \\varepsilon_{mach};$$\n",
    "\n",
    "$$FP(f(x)) = f(x)(1 + \\delta_f),\\hspace{0.5cm} |\\delta_f|\\leq \\varepsilon_{mach};$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$Error_{FP} = \\left | \\frac{FP(f(x+h)) - FP(f(x))}{h} - \\frac{f(x+h) - f(x)}{h}\\right |$$\n",
    "\n",
    "$$\\cdots = \\frac{|f(x+h)\\delta_h - f(x)\\delta_f|}{h}$$\n",
    "\n",
    "$$\\cdots \\leq \\frac{|f(x+h)||\\delta_h| + |f(x)||\\delta_f|}{h}$$\n",
    "\n",
    "$$\\cdots \\leq \\frac{|f(x+h)| + |f(x)|}{h}\\varepsilon_{mach}$$\n",
    "\n",
    "$$Error_{FP} \\leq \\frac{2|f(x)|\\varepsilon_{mach}}{h}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to what was seen for the truncation error, this error is inversely proportional to the step. This means that too small step increases the related error to the representation in floating point. Thus, this analysis combines opposing contraints, since on the one hand a small step is required to minimize the truncation error, but on the other a step too small complicated the work in floating point.\n",
    "Therefore, the total error combining both souces of error can be limited by:\n",
    "\n",
    "$$Error_{total} \\leq \\frac{2|f(x)|\\varepsilon_{mach}}{h} + \\frac{|f''(x)|}{2}h$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal step\n",
    "Since h can be chosen, it is important to find the value of h that minimeze the upper bound of the total error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/hopt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidates to minimize the dimension are those that cancel the first derivative:\n",
    "\n",
    "$$\\frac{dError}{dh} = 0 \\Leftrightarrow \\frac{-2|f(x)|\\varepsilon_{mach}}{h^2} + \\frac{|f''(x)|}{2} = 0$$\n",
    "\n",
    "Clearing:\n",
    "\n",
    "$$h_{opt} = 2\\sqrt{\\frac{|f(x)|}{|f''(x)|}} \\sqrt{\\varepsilon_{mach}}$$\n",
    "\n",
    "Since the second derivative is positive, it is concluded that the error level achives a minimun value at $h = h_{opt}$. In the practise, since we want to approximate $f'(x)$, we may not know the value of $f''(x)$. This means that we cannot use the expression found ofr calculate the optimal step. However, it might happen that we know something about the function second derivative, which allows us to use the result obtained. For instance:\n",
    "\n",
    "If we know: $$|f''(x)| \\approx |f(x)| \\Rightarrow h_{opt} \\approx 2\\sqrt{\\varepsilon_{mach}}$$\n",
    "\n",
    "This occurs, for example, for the sine and cosine functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
